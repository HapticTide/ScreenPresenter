//
//  VideoToolboxDecoder.swift
//  ScreenPresenter
//
//  Created by Sun on 2025/12/24.
//
//  VideoToolbox ç¡¬ä»¶è§£ç å™¨
//  ä½¿ç”¨ Apple VideoToolbox è¿›è¡Œ H.264/H.265 ç¡¬ä»¶åŠ é€Ÿè§£ç 
//

import CoreMedia
import CoreVideo
import Foundation
import QuartzCore
import VideoToolbox

// MARK: - è§£ç å™¨çŠ¶æ€

/// VideoToolbox è§£ç å™¨çŠ¶æ€
enum VideoToolboxDecoderState {
    case idle
    case ready
    case decoding
    case error(Error)
}

// MARK: - è§£ç å™¨é”™è¯¯

/// VideoToolbox è§£ç å™¨é”™è¯¯
enum VideoToolboxDecoderError: LocalizedError {
    case formatDescriptionCreationFailed(OSStatus)
    case sessionCreationFailed(OSStatus)
    case blockBufferCreationFailed(OSStatus)
    case sampleBufferCreationFailed(OSStatus)
    case decodeFailed(OSStatus)
    case missingParameterSets

    var errorDescription: String? {
        switch self {
        case let .formatDescriptionCreationFailed(status):
            "æ ¼å¼æè¿°åˆ›å»ºå¤±è´¥ï¼Œé”™è¯¯ç : \(status)"
        case let .sessionCreationFailed(status):
            "è§£ç ä¼šè¯åˆ›å»ºå¤±è´¥ï¼Œé”™è¯¯ç : \(status)"
        case let .blockBufferCreationFailed(status):
            "BlockBuffer åˆ›å»ºå¤±è´¥ï¼Œé”™è¯¯ç : \(status)"
        case let .sampleBufferCreationFailed(status):
            "SampleBuffer åˆ›å»ºå¤±è´¥ï¼Œé”™è¯¯ç : \(status)"
        case let .decodeFailed(status):
            "è§£ç å¤±è´¥ï¼Œé”™è¯¯ç : \(status)"
        case .missingParameterSets:
            "ç¼ºå°‘å‚æ•°é›†ï¼ˆSPS/PPSï¼‰"
        }
    }
}

// MARK: - VideoToolbox è§£ç å™¨

/// VideoToolbox ç¡¬ä»¶è§£ç å™¨
/// æ¥æ”¶ AVCC æ ¼å¼çš„ç¼–ç æ•°æ®ï¼Œè¾“å‡º CVPixelBuffer
final class VideoToolboxDecoder {
    // MARK: - å±æ€§

    /// ç¼–è§£ç ç±»å‹
    private let codecType: CMVideoCodecType

    /// æ ¼å¼æè¿°
    private var formatDescription: CMVideoFormatDescription?

    /// è§£å‹ç¼©ä¼šè¯
    private var decompressionSession: VTDecompressionSession?

    /// å½“å‰çŠ¶æ€
    private(set) var state: VideoToolboxDecoderState = .idle

    /// è§£ç é˜Ÿåˆ—
    private let decodeQueue = DispatchQueue(
        label: "com.screenPresenter.videoToolbox.decode",
        qos: .userInteractive
    )

    /// çŠ¶æ€é”
    private let stateLock = NSLock()

    /// è§£ç åçš„å¸§å›è°ƒï¼ˆåœ¨ decodeQueue ä¸Šè°ƒç”¨ï¼‰
    var onDecodedFrame: ((CVPixelBuffer) -> Void)?

    /// è§£ç ç»Ÿè®¡
    private(set) var decodedFrameCount = 0
    private(set) var failedFrameCount = 0
    private(set) var droppedFrameCount = 0

    // MARK: - ä¸¢å¸§ç­–ç•¥

    /// æœ€å¤§å¾…è§£ç å¸§æ•°ï¼ˆè¶…è¿‡æ­¤å€¼å°†ä¸¢å¼ƒéå…³é”®å¸§ï¼‰
    private let maxPendingFrames = 3

    /// å½“å‰å¾…è§£ç å¸§è®¡æ•°
    private var pendingFrameCount = 0

    /// å¾…è§£ç å¸§è®¡æ•°é”
    private let pendingLock = NSLock()

    // MARK: - åˆå§‹åŒ–

    /// åˆå§‹åŒ–è§£ç å™¨
    /// - Parameter codecType: ç¼–è§£ç ç±»å‹ï¼ˆkCMVideoCodecType_H264 æˆ– kCMVideoCodecType_HEVCï¼‰
    init(codecType: CMVideoCodecType) {
        self.codecType = codecType
        AppLogger.capture.info("[VTDecoder] åˆå§‹åŒ–ï¼Œç¼–è§£ç å™¨: \(codecType == kCMVideoCodecType_H264 ? "H.264" : "H.265")")
    }

    deinit {
        invalidateSession()
        AppLogger.capture
            .info("[VTDecoder] é”€æ¯ï¼Œè§£ç : \(decodedFrameCount), å¤±è´¥: \(failedFrameCount), ä¸¢å¼ƒ: \(droppedFrameCount)")
    }

    // MARK: - å…¬å¼€æ–¹æ³•

    /// ä½¿ç”¨ H.264 å‚æ•°é›†åˆå§‹åŒ–è§£ç å™¨
    /// - Parameters:
    ///   - sps: SPS æ•°æ®
    ///   - pps: PPS æ•°æ®
    func initializeH264(sps: Data, pps: Data) throws {
        print("ğŸ”§ [VTDecoder] ä½¿ç”¨ H.264 å‚æ•°é›†åˆå§‹åŒ–ï¼ŒSPS: \(sps.count)B, PPS: \(pps.count)B")
        AppLogger.capture.info("[VTDecoder] ä½¿ç”¨ H.264 å‚æ•°é›†åˆå§‹åŒ–ï¼ŒSPS: \(sps.count)B, PPS: \(pps.count)B")

        guard let formatDesc = VideoFormatDescriptionFactory.createH264FormatDescription(sps: sps, pps: pps) else {
            print("âŒ [VTDecoder] æ ¼å¼æè¿°åˆ›å»ºå¤±è´¥")
            throw VideoToolboxDecoderError.formatDescriptionCreationFailed(-1)
        }
        print("âœ… [VTDecoder] æ ¼å¼æè¿°åˆ›å»ºæˆåŠŸ")

        formatDescription = formatDesc
        try createDecompressionSession(formatDescription: formatDesc)

        updateState(.ready)
        print("âœ… [VTDecoder] H.264 è§£ç å™¨åˆå§‹åŒ–æˆåŠŸï¼ŒçŠ¶æ€: \(state)")
        AppLogger.capture.info("[VTDecoder] âœ… H.264 è§£ç å™¨åˆå§‹åŒ–æˆåŠŸ")
    }

    /// ä½¿ç”¨ H.265 å‚æ•°é›†åˆå§‹åŒ–è§£ç å™¨
    /// - Parameters:
    ///   - vps: VPS æ•°æ®
    ///   - sps: SPS æ•°æ®
    ///   - pps: PPS æ•°æ®
    func initializeH265(vps: Data, sps: Data, pps: Data) throws {
        AppLogger.capture.info("[VTDecoder] ä½¿ç”¨ H.265 å‚æ•°é›†åˆå§‹åŒ–ï¼ŒVPS: \(vps.count)B, SPS: \(sps.count)B, PPS: \(pps.count)B")

        guard let formatDesc = VideoFormatDescriptionFactory.createH265FormatDescription(vps: vps, sps: sps, pps: pps)
        else {
            throw VideoToolboxDecoderError.formatDescriptionCreationFailed(-1)
        }

        formatDescription = formatDesc
        try createDecompressionSession(formatDescription: formatDesc)

        updateState(.ready)
        AppLogger.capture.info("[VTDecoder] âœ… H.265 è§£ç å™¨åˆå§‹åŒ–æˆåŠŸ")
    }

    /// è§£ç  NAL å•å…ƒ
    /// - Parameters:
    ///   - nalUnit: è§£æåçš„ NAL å•å…ƒ
    ///   - presentationTime: æ˜¾ç¤ºæ—¶é—´ï¼ˆå¯é€‰ï¼‰
    func decode(nalUnit: ParsedNALUnit, presentationTime: CMTime? = nil) {
        // è·³è¿‡å‚æ•°é›†
        guard !nalUnit.isParameterSet else { return }

        // ä¸¢å¸§ç­–ç•¥ï¼šå¦‚æœå¾…è§£ç å¸§è¿‡å¤šï¼Œä¸¢å¼ƒéå…³é”®å¸§
        pendingLock.lock()
        let currentPending = pendingFrameCount
        pendingLock.unlock()

        if currentPending > maxPendingFrames, !nalUnit.isKeyFrame {
            droppedFrameCount += 1
            if droppedFrameCount % 30 == 1 {
                AppLogger.capture.warning("[VTDecoder] ä¸¢å¼ƒéå…³é”®å¸§ï¼Œå¾…è§£ç : \(currentPending), å·²ä¸¢å¼ƒ: \(droppedFrameCount)")
            }
            return
        }

        pendingLock.lock()
        pendingFrameCount += 1
        pendingLock.unlock()

        decodeQueue.async { [weak self] in
            defer {
                self?.pendingLock.lock()
                self?.pendingFrameCount -= 1
                self?.pendingLock.unlock()
            }
            self?.decodeNALUnitSync(nalUnit: nalUnit, presentationTime: presentationTime)
        }
    }

    /// è§£ç  AVCC æ ¼å¼æ•°æ®
    /// - Parameters:
    ///   - avccData: AVCC æ ¼å¼çš„ç¼–ç æ•°æ®ï¼ˆ4å­—èŠ‚é•¿åº¦å‰ç¼€ + NAL æ•°æ®ï¼‰
    ///   - isKeyFrame: æ˜¯å¦ä¸ºå…³é”®å¸§
    ///   - presentationTime: æ˜¾ç¤ºæ—¶é—´ï¼ˆå¯é€‰ï¼‰
    func decode(avccData: Data, isKeyFrame: Bool, presentationTime: CMTime? = nil) {
        decodeQueue.async { [weak self] in
            self?.decodeAVCCDataSync(avccData: avccData, isKeyFrame: isKeyFrame, presentationTime: presentationTime)
        }
    }

    /// åˆ·æ–°è§£ç å™¨ï¼ˆç­‰å¾…æ‰€æœ‰å¸§è§£ç å®Œæˆï¼‰
    func flush() {
        decodeQueue.sync { [weak self] in
            guard let session = self?.decompressionSession else { return }
            VTDecompressionSessionWaitForAsynchronousFrames(session)
        }
    }

    /// é‡ç½®è§£ç å™¨
    func reset() {
        invalidateSession()
        formatDescription = nil
        decodedFrameCount = 0
        failedFrameCount = 0
        droppedFrameCount = 0
        pendingLock.lock()
        pendingFrameCount = 0
        pendingLock.unlock()
        updateState(.idle)
        AppLogger.capture.info("[VTDecoder] å·²é‡ç½®")
    }

    /// è§£ç å™¨æ˜¯å¦å·²å°±ç»ª
    var isReady: Bool {
        if case .ready = state { return true }
        if case .decoding = state { return true }
        return false
    }

    // MARK: - ç§æœ‰æ–¹æ³•

    /// æ›´æ–°çŠ¶æ€
    private func updateState(_ newState: VideoToolboxDecoderState) {
        stateLock.lock()
        state = newState
        stateLock.unlock()
    }

    /// åˆ›å»ºè§£å‹ç¼©ä¼šè¯
    private func createDecompressionSession(formatDescription: CMFormatDescription) throws {
        // å…ˆé”€æ¯æ—§çš„ä¼šè¯
        invalidateSession()

        // è¾“å‡ºé…ç½®
        let outputPixelBufferAttributes: [String: Any] = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
            kCVPixelBufferMetalCompatibilityKey as String: true,
        ]

        // åˆ›å»ºå›è°ƒ
        var outputCallback = VTDecompressionOutputCallbackRecord(
            decompressionOutputCallback: { refcon, _, status, _, imageBuffer, _, _ in
                guard let refcon else { return }

                let decoder = Unmanaged<VideoToolboxDecoder>.fromOpaque(refcon).takeUnretainedValue()

                if status == noErr, let imageBuffer {
                    decoder.decodedFrameCount += 1
                    if decoder.decodedFrameCount <= 3 {
                        print("ğŸ¬ [VTDecoder] è§£ç æˆåŠŸ #\(decoder.decodedFrameCount)")
                    }
                    decoder.onDecodedFrame?(imageBuffer)
                } else {
                    decoder.failedFrameCount += 1
                    print("âŒ [VTDecoder] è§£ç å¤±è´¥ #\(decoder.failedFrameCount)ï¼ŒçŠ¶æ€: \(status)")
                    if status != noErr {
                        AppLogger.capture.warning("[VTDecoder] è§£ç å›è°ƒé”™è¯¯: \(status)")
                    }
                }
            },
            decompressionOutputRefCon: Unmanaged.passUnretained(self).toOpaque()
        )

        var session: VTDecompressionSession?
        let status = VTDecompressionSessionCreate(
            allocator: kCFAllocatorDefault,
            formatDescription: formatDescription,
            decoderSpecification: nil,
            imageBufferAttributes: outputPixelBufferAttributes as CFDictionary,
            outputCallback: &outputCallback,
            decompressionSessionOut: &session
        )

        guard status == noErr, let session else {
            throw VideoToolboxDecoderError.sessionCreationFailed(status)
        }

        decompressionSession = session
        AppLogger.capture.info("[VTDecoder] è§£å‹ç¼©ä¼šè¯å·²åˆ›å»º")
    }

    /// é”€æ¯è§£å‹ç¼©ä¼šè¯
    private func invalidateSession() {
        if let session = decompressionSession {
            VTDecompressionSessionInvalidate(session)
            decompressionSession = nil
            AppLogger.capture.info("[VTDecoder] è§£å‹ç¼©ä¼šè¯å·²é”€æ¯")
        }
    }

    /// åŒæ­¥è§£ç  NAL å•å…ƒ
    private func decodeNALUnitSync(nalUnit: ParsedNALUnit, presentationTime: CMTime?) {
        // è½¬æ¢ä¸º AVCC æ ¼å¼
        let avccData = AnnexBToAVCCConverter.convert(nalUnit.data)
        decodeAVCCDataSync(avccData: avccData, isKeyFrame: nalUnit.isKeyFrame, presentationTime: presentationTime)
    }

    /// åŒæ­¥è§£ç  AVCC æ•°æ®
    private func decodeAVCCDataSync(avccData: Data, isKeyFrame: Bool, presentationTime: CMTime?) {
        guard let session = decompressionSession, let formatDesc = formatDescription else {
            return
        }

        updateState(.decoding)

        // åˆ›å»º CMBlockBuffer
        var blockBuffer: CMBlockBuffer?

        let blockBufferStatus = avccData.withUnsafeBytes { buffer -> OSStatus in
            // å¿…é¡»å¤åˆ¶æ•°æ®ï¼Œå› ä¸º CMBlockBuffer ä¸æ‹¥æœ‰æ•°æ®
            CMBlockBufferCreateWithMemoryBlock(
                allocator: kCFAllocatorDefault,
                memoryBlock: nil,
                blockLength: buffer.count,
                blockAllocator: kCFAllocatorDefault,
                customBlockSource: nil,
                offsetToData: 0,
                dataLength: buffer.count,
                flags: 0,
                blockBufferOut: &blockBuffer
            )
        }

        guard blockBufferStatus == kCMBlockBufferNoErr, let buffer = blockBuffer else {
            failedFrameCount += 1
            return
        }

        // å¤åˆ¶æ•°æ®åˆ° block buffer
        avccData.withUnsafeBytes { dataBuffer in
            _ = CMBlockBufferReplaceDataBytes(
                with: dataBuffer.baseAddress!,
                blockBuffer: buffer,
                offsetIntoDestination: 0,
                dataLength: dataBuffer.count
            )
        }

        // åˆ›å»º CMSampleBuffer
        var sampleBuffer: CMSampleBuffer?
        let pts = presentationTime ?? CMTime(value: Int64(CACurrentMediaTime() * 1_000_000), timescale: 1_000_000)

        var timingInfo = CMSampleTimingInfo(
            duration: CMTime.invalid,
            presentationTimeStamp: pts,
            decodeTimeStamp: CMTime.invalid
        )

        var sampleSize = avccData.count
        let sampleBufferStatus = CMSampleBufferCreateReady(
            allocator: kCFAllocatorDefault,
            dataBuffer: buffer,
            formatDescription: formatDesc,
            sampleCount: 1,
            sampleTimingEntryCount: 1,
            sampleTimingArray: &timingInfo,
            sampleSizeEntryCount: 1,
            sampleSizeArray: &sampleSize,
            sampleBufferOut: &sampleBuffer
        )

        guard sampleBufferStatus == noErr, let sample = sampleBuffer else {
            failedFrameCount += 1
            return
        }

        // è®¾ç½®å…³é”®å¸§æ ‡è®°
        if isKeyFrame {
            let attachments = CMSampleBufferGetSampleAttachmentsArray(sample, createIfNecessary: true)
            if let attachments, CFArrayGetCount(attachments) > 0 {
                let dict = unsafeBitCast(CFArrayGetValueAtIndex(attachments, 0), to: CFMutableDictionary.self)
                CFDictionarySetValue(
                    dict,
                    Unmanaged.passUnretained(kCMSampleAttachmentKey_NotSync).toOpaque(),
                    Unmanaged.passUnretained(kCFBooleanFalse).toOpaque()
                )
            }
        }

        // è§£ç 
        let decodeFlags: VTDecodeFrameFlags = [._EnableAsynchronousDecompression]
        var infoFlags: VTDecodeInfoFlags = []

        let decodeStatus = VTDecompressionSessionDecodeFrame(
            session,
            sampleBuffer: sample,
            flags: decodeFlags,
            frameRefcon: nil,
            infoFlagsOut: &infoFlags
        )

        if decodeStatus != noErr {
            failedFrameCount += 1
            AppLogger.capture.warning("[VTDecoder] è§£ç å¤±è´¥: \(decodeStatus)")
        }
    }
}
